{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Get the link for all shows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Define a function to get the links of all pages for an artist\n",
    "##### Only 10 shows are displayed per page, so we need to get url for all pages first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_all_page_links(artist_name):\n",
    "\n",
    "    page_links = list()\n",
    "    if ' ' in artist_name:\n",
    "        artist_name = artist_name.replace(\" \", \"%20\")        \n",
    "    url = \"https://www.setlist.fm/search?query=\" + artist_name\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to connect with website\")\n",
    "    \n",
    "    results_page = BeautifulSoup(response.content, 'lxml')\n",
    "    \n",
    "    total_num_pages =  results_page.find_all('div', class_='col-xs-12 noTopBorder noTopPadding hidden-print text-center listPager-lg')\n",
    "    li_list = total_num_pages[0].find_all('li')\n",
    "    last_page_text = int(li_list[8].get_text())\n",
    "    \n",
    "    for num in range(2,last_page_text + 1 ):\n",
    "                show_page = 'https://www.setlist.fm/search?page=' + str(num) + '&query=' + artist_name\n",
    "                page_links.append(show_page)\n",
    "    \n",
    "    page_links.insert(0, url)\n",
    "        \n",
    "    return page_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Define a function to get the links for all shows\n",
    "##### We iterate on all pages and for each page we extract the url of all shows, then we put them in a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_show_links(page_links):\n",
    "    \n",
    "    show_links_list = list()\n",
    "    \n",
    "    for link in page_links:\n",
    "        response = requests.get(link)\n",
    "        if response.status_code != 200:\n",
    "            print(\"Failed to connect with website\")\n",
    "        results_page = BeautifulSoup(response.content, 'lxml')\n",
    "        try:\n",
    "            messy_list_show_links = results_page.find_all('div', class_='row contentBox visiblePrint')[0].find_all('h2')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            for show in messy_list_show_links:    \n",
    "                try:\n",
    "                    raw_url = show.find('a').get('href')\n",
    "                    raw_url = raw_url.lstrip(\"..\") \n",
    "                    actual_url = 'https://www.setlist.fm/'+ raw_url \n",
    "                    show_links_list.append(actual_url)\n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return show_links_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_shows = create_list_show_links(grab_all_page_links('billy joel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Extract info for shows and populate a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: Define a function to get show info given a link\n",
    "##### We scrap the data and put it in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_show_info(url):\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(response.status_code)\n",
    "        results_page = BeautifulSoup(response.content, 'lxml')\n",
    "    except requests.Timeout as e:\n",
    "        print(\"It is time to timeout\")\n",
    "        print(str(e))\n",
    "        pass\n",
    "    \n",
    "    all_show_info = list()\n",
    "    \n",
    "    #Part 1 -- Get the date \n",
    "    try:\n",
    "        full_date = results_page.find_all('div', class_=\"breadCrumbBar\")[0].find_all('span')[-1].get_text().rstrip('Setlist')\n",
    "        month, day, year = full_date.strip().replace(\",\",\"\").split(\" \")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Create a tuple of the date info and add it to the all_show_info list\n",
    "    try:\n",
    "        date_tuple = (month, day, year)\n",
    "        all_show_info.append(date_tuple)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Part 2 -- Get the location info\n",
    "    try:\n",
    "        header_info = results_page.find('h1').find_all('span')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        location_info = header_info[3].find('span').get_text()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        venue, city, state, country = location_info.split(\",\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        location_tuple = (venue, city, state, country) \n",
    "        all_show_info.append(location_tuple)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    #Part 3 -- Get the songs\n",
    "    setlist = list()\n",
    "    try:\n",
    "        set_list_list = results_page.find_all('a', 'songLabel')\n",
    "        for song in set_list_list:\n",
    "            setlist.append(song.get_text())\n",
    "   \n",
    "        setlist_tuple = tuple(setlist)\n",
    "        all_show_info.append(setlist_tuple)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return all_show_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Build an empty dataframe\n",
    "##### We list all songs and make columns named after them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = list()\n",
    "for show in list_of_shows:\n",
    "    set_list = get_all_show_info(show)[-1]\n",
    "    all_songs.extend(set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs_unique = list(set(all_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = ['Year','Month','Day','Venue','City','State','Country'] + all_songs_unique\n",
    "df = pd.DataFrame(columns = column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3: Populate the dataframe\n",
    "##### We iterate on the list of show links and fill the dataframe, with a 1 in the corresponding column if a song has been played during that show (else we set the value to 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Gauthier\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for show_num in range(len(list_of_shows)):\n",
    "    all_show_info = get_all_show_info(list_of_shows[show_num])\n",
    "    df = df.append({'Year': 0}, ignore_index=True)\n",
    "    df['Year'][show_num] = all_show_info[0][2]\n",
    "    df['Month'][show_num] = all_show_info[0][0]\n",
    "    df['Day'][show_num] = all_show_info[0][1]\n",
    "    if len(all_show_info) == 3:\n",
    "        df['Venue'][show_num] = all_show_info[1][0]\n",
    "        df['City'][show_num] = all_show_info[1][1]\n",
    "        df['State'][show_num] = all_show_info[1][2]\n",
    "        df['Country'][show_num] = all_show_info[1][3]\n",
    "    for column in all_songs_unique:\n",
    "        df[column][show_num] = 0\n",
    "    for song in all_show_info[-1]:\n",
    "        df[song][show_num] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Venue</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Anchors Aweigh</th>\n",
       "      <th>Gimme Some Lovin'</th>\n",
       "      <th>Whole Lotta Love</th>\n",
       "      <th>...</th>\n",
       "      <th>Angels We Have Heard On High</th>\n",
       "      <th>Pop Goes the Weasel / Circus Music / Angelina / Zooma Zooma / Pop Goes the Weasel</th>\n",
       "      <th>The Mexican Connection</th>\n",
       "      <th>Bohemian Rhapsody</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>The Night Is Still Young</th>\n",
       "      <th>Honky Cat</th>\n",
       "      <th>Somewhere Along the Line</th>\n",
       "      <th>Me and Julio Down by the Schoolyard</th>\n",
       "      <th>Sherry / Unchained Melody / Speedoo / The Lion Sleeps Tonight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>November</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Madison Square Garden</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>October</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Madison Square Garden</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 538 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year     Month   Day                  Venue       City State Country  \\\n",
       "0  2018.0  November  10.0  Madison Square Garden   New York    NY     USA   \n",
       "1  2018.0   October  27.0  Madison Square Garden   New York    NY     USA   \n",
       "2     0.0       NaN   NaN                    NaN        NaN   NaN     NaN   \n",
       "\n",
       "   Anchors Aweigh  Gimme Some Lovin'  Whole Lotta Love  \\\n",
       "0             0.0                0.0               0.0   \n",
       "1             0.0                0.0               0.0   \n",
       "2             NaN                NaN               NaN   \n",
       "\n",
       "                               ...                                \\\n",
       "0                              ...                                 \n",
       "1                              ...                                 \n",
       "2                              ...                                 \n",
       "\n",
       "   Angels We Have Heard On High  \\\n",
       "0                           0.0   \n",
       "1                           0.0   \n",
       "2                           NaN   \n",
       "\n",
       "   Pop Goes the Weasel / Circus Music / Angelina / Zooma Zooma / Pop Goes the Weasel  \\\n",
       "0                                                0.0                                   \n",
       "1                                                0.0                                   \n",
       "2                                                NaN                                   \n",
       "\n",
       "   The Mexican Connection  Bohemian Rhapsody  Pressure  \\\n",
       "0                     0.0                1.0       0.0   \n",
       "1                     0.0                0.0       0.0   \n",
       "2                     NaN                NaN       NaN   \n",
       "\n",
       "   The Night Is Still Young  Honky Cat  Somewhere Along the Line  \\\n",
       "0                       0.0        0.0                       0.0   \n",
       "1                       0.0        0.0                       0.0   \n",
       "2                       NaN        NaN                       NaN   \n",
       "\n",
       "   Me and Julio Down by the Schoolyard  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  NaN   \n",
       "\n",
       "   Sherry / Unchained Melody / Speedoo / The Lion Sleeps Tonight  \n",
       "0                                                0.0              \n",
       "1                                                0.0              \n",
       "2                                                NaN              \n",
       "\n",
       "[3 rows x 538 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
